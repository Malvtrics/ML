RNN条件生成解决的问题：图片生成，文本分类，机器翻译，视频解说

输入一张图像 输出许多文本
输入许多文本 输出情感分类
输入英文文本 输出中文文本 非实时的，需要全部输入后再预测
多对多 输入法预测下一个要输入的字 实时的

条件生成不是生成网络，一般说生成网络是GAN
机器翻译中生成很多句子，然后有个评分的模型对句子打分，输出那个打分最高的句子
attention机制和seq2seq机制使得机器翻译越来越准确

encoder->decoder 模型
embedding -> endcoder -> s -> (begin of sentence -> BOS (机器翻译的第一个单词NULL))decoder -> softmax
实际工程中lstm参数比较大，所以在手机上这个模型不是很受欢迎,所以可以用GRU,GRU的参数会少一些，还可以用CIFG(下面LSTM变体之一) 为啥用需要查？？？
缺点1：s是一个向量 可能1024或者2048 但是有时候输入的句子中一个单词可能就有这么多信息，更何况是一个句子，所以会造成信息丢失
      =》行内人说法：定长编码是信息瓶颈
      这个为啥？？？完了深入研究下遗忘门
缺点2：离s比较近的单词，被保留下来的概率比较大=》行内人说法：长度越长，前面进入RNN的信息越被稀释 

LSTM的变体
1、没有输入门（NIG）
2、没有遗忘门（NFG）
3、没有输出门（NOG）
4、没有输入激活函数（NIAF）
5、没有输出激活函数（NOAF）
6、没有peepholes（NP）
7、耦合输入门和遗忘门（CIFG）
8、Full Gate Recurrent（FGR）

attention_based encoder-decoder
加入attention机制，使得encoder的时候可以用到decoder时候句子中所有单词的信息
缺点：当句子很长的时候，计算量比较大，所以有时候不用global attention用的是局部 local attention

下面的改进都是对encoder的改进，整个模型的好不好很大程度上取决于encoder的设计
bi-direcional decode layer 在decoder的时候用了双向RNN
所有上述双向RNN网络的一个主要问题是，它们从之前的时间步骤中学习表示。
有时，你有可能需要从未来的时间步骤中学习表示，以便更好地理解上下文环境并消除歧义。
通过接下来的列子，“He said, Teddy bears are on sale” and “He said, Teddy Roosevelt was a great President。
在上面的两句话中，当我们看到“Teddy”和前两个词“He said”的时候，我们有可能无法理解这个句子是指President还是Teddy bears。
因此，为了解决这种歧义性，我们需要往前查找。这就是双向RNN所能实现的。

继续改进 用残差网络  residual encode layer
encoder用多层残差网 encoder-》sum -> encoder -> sum ......
继续改进就得到了google 机器翻译的大概模型

encoder 部分用residual encode layer , 同时残差层之间也是有链接的，然后输出到attention
问题：attention的计算和attention的加权计算  具体可能要去看源代码？？？？先把大概的过程记在这里：
encoder LSTM 的输出 [a_i,...a_n] 
decoder 中每步的输出 h_i
alpha = [tanh(w1*a_j+w2*h_i) for j in range(n)]
w1和w2是可以用梯度下降法去更新的权重

继续改进 修改attention的机制
之前的attention机制有 global 和 local
现在我们引入self attention
why? tranditional attention only cares the relationship between source and target 
但是忽略了source和target自己的attention-> 理解：比如输入的一个句子当中，一个单词的语义比另外一个更加丰富
其实主要是一个句子中单词和单词之间的关联关系

另外一种hierachical attention 以文本分类为例子
分层： 词到句 word encoder-> word attention-> sentence encoder-> sentence attention
分层： 句子到段落-> 类似上面
所以一共有四种attention global local self hierachical 

图像生成文本的需求
百度开发的M-RNN
可以用来玩耍的数据集：
      IAPR TC-12       Flickr8k      Flickr30k         MS COCO     AI Challenger(图像有中文描述数据)
评测标准 BLEU score bilingual evaluation understudy 双语翻译质量辅助工具
https://blog.csdn.net/allocator/article/details/79657792
multi-model RNN 百度第一次将CNN应用到图像生成文本领域
会先用到一个训练好的CNN来预测
输入词生成embedding 
embedding输入到RNN和multi-model
RNN生成更加抽象的embedding
原始embedding RNN生成的embedding 和图像的feature同时输入给分类层

斯坦福大学的 show and tell 模型
使用google-net对输入图像做特征提取
图像特征只提取一次
用LSTM来生成文本

show attend and tell 模型
top-down bottom-up attention 模型
这两个模型听得云里雾里的，还要继续深化 要继续看论文

tensorflow 和 theato是静态的网络结构 dynet是动态的网络结构
https://blog.csdn.net/stdcoutzyx
