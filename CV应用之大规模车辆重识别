triplet loss 
CNN是通过softmax来解决排序的问题，想想是不是有哪里不太一样？
对于某一个神经网络，我的输入是带有三个输
怎么理解embedding??
https://www.zhihu.com/question/38002635

Euclidean space 欧式空间
harmonic embeddings 谐波嵌入
off the shelf 现成的
bottleneck layer 瓶颈层 输入输出维度差距较大，就像一个瓶颈一样，上窄下宽亦或上宽下窄，深入理解下如下链接
https://blog.csdn.net/u011501388/article/details/80389164

cross level vehicle recongnition CLVR
robotics
myriad 无数的

数据扩增的包 imgaug 数据增强库 网上有对应的学习笔记

如果现在有一个车辆识别任务

method1: train convnets to predict vehicle models
training 就直接用inception v3

start with a convnet (eg.inception v3) initialized with imagenet pretrained weights
remove the lsat fully-connected layers 
extract the 2048-d features by adding a gloable average polling layer after the last convolutional layer
adding the output layer for predicting vehicle models which is a fully-connected layer

裁剪图片的时候 a better way : 因为图片很多情况下是长方形，不能直接选中中心位置，不然不准确，
所以先确定短边，然后按照比例找中间的小长方形，然后已中心位置旋转90度，两个长方形交叠的正方形为最后裁剪结果
we call this method as center-crop 
但是这样的问题是：如果每次选取中心位置，那么信息可能有丢失
为了保证每次都能训练到不同的位置，在实际操作过程中，会用padding去做一些补零的操作，然后每次随机去做移动，这样每次训练都可以得到不同的区域

进阶method2: 利用颜色数据做多任务学习
凡是神经网络有两个以上输出分支的我们call it multi-task learning
这里我们输出车型和颜色两个分支 颜色更加容易学习，所以在实际操作中可以降低权重

进阶method3：multi-task learning = triple loss + cross-entropy

在实际训练中，我们如何准备我们得negative数据呢？
比如一张图片是白色大众帕萨特，它的negative如果是红色奥迪，其实在上面的multi-task learning中
我们已经可以根据颜色分支区别出来，所以我们要选取一些hard negative的输入样本，
比如白色奥迪，这样可以更加高效的利用负样本，让模型可区分的颗粒度更细

结论：你想让模型区分哪些方面？就喂给模型什么样的数据，否则triplet loss没办法发挥作用

